{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SNR_1c.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hm4MESC0Yf-z","colab_type":"code","colab":{}},"source":["#################################################################################################\n","#     TASK 1C. Building SVM classifiers based on Pre-trained Alexnet network\n","#     For different SVM kernels: \n","#              + Linear, \n","#              + Quadratic,\n","#              + Polynomial\n","#################################################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUMj6PhJYiQw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592565056945,"user_tz":-120,"elapsed":548,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"d62f40e7-f685-4382-a27b-14d5948a1d58"},"source":["# 1. Mount the data from Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XCoKSYgYYjxb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592565060834,"user_tz":-120,"elapsed":530,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"fd6560c4-54f3-453f-a4e1-34d1e0d3d0c8"},"source":["# 2. Change working directory\n","%cd drive/My\\ Drive/Colab\\ Notebooks/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eo9fkeufPVoI","pycharm":{"is_executing":false},"colab":{},"executionInfo":{"status":"ok","timestamp":1592565064719,"user_tz":-120,"elapsed":1580,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["# Import necessary packages for the task\n","from __future__ import print_function, division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","from numpy import where\n","import pandas as pd\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","from torch.autograd import Variable\n","from random import randrange\n","from matplotlib.pyplot import figure\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.svm import SVC\n","from sklearn.pipeline import Pipeline\n","from pylab import scatter, show, legend, xlabel, ylabel"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0jRCcRfuPqs3","pycharm":{"is_executing":false},"colab":{},"executionInfo":{"status":"ok","timestamp":1592565076809,"user_tz":-120,"elapsed":622,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["# Data augmentation and normalization for training data\n","\n","# transforms.RandomResizedCrop(224),\n","#         transforms.RandomHorizontalFlip(),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","# Just normalization for validation\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","data_dir = 'flowers_alexnet_dataset'\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: torch.utils.data.DataLoader( image_datasets[x], batch_size=4,\n","                                            shuffle=True, num_workers=4)\n","              for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WvlTJHi31uYC","colab":{},"executionInfo":{"status":"ok","timestamp":1592565083599,"user_tz":-120,"elapsed":3692,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["# Create pre-trained Alexnet network\n","model = models.alexnet(pretrained=True)\n","\n","num_fts = model.classifier[6].out_features\n","\n","# add full-connected layer to the net\n","model.fc = nn.Linear(num_fts, num_fts)\n","\n","# init the weights for the fc layer\n","torch.nn.init.eye_(model.fc.weight)\n","\n","# keep all weights fixed\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# add the model to the device\n","model = model.to(device)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"NF-itJF4FDw0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592565093654,"user_tz":-120,"elapsed":2499,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["# Create pre-trained Alexnet network by removing all classifiers and\n","# replace by 1 Linear classifier to extract features for transfer learning\n","model = models.alexnet(pretrained=True)\n","\n","num_fts = model.classifier[1].in_features\n","\n","# add a new classifier layer to the net\n","model.classifier = nn.Linear(num_fts, num_fts)\n","\n","# init the weights for the fc layer\n","torch.nn.init.eye_(model.classifier.weight)\n","\n","# keep all weights fixed\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# add the model to the device\n","model = model.to(device)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hj15x3asbtFn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"status":"ok","timestamp":1592565097433,"user_tz":-120,"elapsed":559,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"440d8df1-b42e-4337-9689-f3f9f2a46f22"},"source":["model.eval"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.eval of AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Linear(in_features=9216, out_features=9216, bias=True)\n",")>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k8vGS77xqIir","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592565132435,"user_tz":-120,"elapsed":31974,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"68c2b28f-0f8b-4c30-d5f4-0ef1fd6c219c"},"source":["# Get features from CNN Alexnet network for all training and validation data\n","def get_train_and_val_features():\n","    extracted_features = {\"train\": [], \"val\": []}\n","    # Training and validation phase\n","    for phase in ['train', 'val']:\n","        # Iterate over data.\n","        for inputs, labels in dataloaders[phase]:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # get features outputs\n","            features = model(inputs).cpu()\n","\n","            batch_number = features.shape[0] \n","            \n","            for i in range(0, batch_number):  \n","                featr = np.array(features[i].cpu())\n","                label = int(labels[i].cpu().numpy())                \n","                extracted_features[phase].append(np.append(label, featr))\n","    \n","    return (extracted_features)\n","\n","# Extract features from Alexnet\n","features = get_train_and_val_features()\n","\n","print (len(features))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0ajqrlSqHvQt","colab":{},"executionInfo":{"status":"ok","timestamp":1592565156745,"user_tz":-120,"elapsed":15965,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["# Prepare training and validating data\n","train_dataset = pd.DataFrame()\n","val_dataset = pd.DataFrame()\n","for typ, data in features.items():\n","    if typ == 'train':\n","        train_dataset = pd.DataFrame(data)\n","    if typ == 'val':\n","        val_dataset = pd.DataFrame(data)\n","\n","# training data\n","Y = train_dataset.iloc[:, 0]\n","X = train_dataset.iloc[:, 1:]\n","\n","# validating data\n","Y_val = val_dataset.iloc[:, 0]\n","X_val = val_dataset.iloc[:, 1:]"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_yg4zJD9WyT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":392},"executionInfo":{"status":"ok","timestamp":1592565160416,"user_tz":-120,"elapsed":603,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"e7dd60dd-5f04-492a-ad5e-2a6164fe1278"},"source":["train_dataset.head(10)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>9177</th>\n","      <th>9178</th>\n","      <th>9179</th>\n","      <th>9180</th>\n","      <th>9181</th>\n","      <th>9182</th>\n","      <th>9183</th>\n","      <th>9184</th>\n","      <th>9185</th>\n","      <th>9186</th>\n","      <th>9187</th>\n","      <th>9188</th>\n","      <th>9189</th>\n","      <th>9190</th>\n","      <th>9191</th>\n","      <th>9192</th>\n","      <th>9193</th>\n","      <th>9194</th>\n","      <th>9195</th>\n","      <th>9196</th>\n","      <th>9197</th>\n","      <th>9198</th>\n","      <th>9199</th>\n","      <th>9200</th>\n","      <th>9201</th>\n","      <th>9202</th>\n","      <th>9203</th>\n","      <th>9204</th>\n","      <th>9205</th>\n","      <th>9206</th>\n","      <th>9207</th>\n","      <th>9208</th>\n","      <th>9209</th>\n","      <th>9210</th>\n","      <th>9211</th>\n","      <th>9212</th>\n","      <th>9213</th>\n","      <th>9214</th>\n","      <th>9215</th>\n","      <th>9216</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.0</td>\n","      <td>-0.006222</td>\n","      <td>0.001637</td>\n","      <td>-0.008066</td>\n","      <td>0.002481</td>\n","      <td>0.000470</td>\n","      <td>-0.006442</td>\n","      <td>-0.007088</td>\n","      <td>0.005668</td>\n","      <td>-0.004833</td>\n","      <td>-0.001299</td>\n","      <td>0.000618</td>\n","      <td>-0.004086</td>\n","      <td>0.004436</td>\n","      <td>-0.003153</td>\n","      <td>-0.007243</td>\n","      <td>-0.002162</td>\n","      <td>0.004506</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>0.010352</td>\n","      <td>0.005348</td>\n","      <td>0.008442</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>0.003492</td>\n","      <td>-0.002589</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.005423</td>\n","      <td>-0.008794</td>\n","      <td>-0.008008</td>\n","      <td>0.001326</td>\n","      <td>0.640235</td>\n","      <td>1.584166</td>\n","      <td>-0.003758</td>\n","      <td>-0.003128</td>\n","      <td>0.000260</td>\n","      <td>...</td>\n","      <td>1.459623</td>\n","      <td>0.783452</td>\n","      <td>0.333820</td>\n","      <td>2.533830</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>2.563910</td>\n","      <td>2.562145</td>\n","      <td>0.001465</td>\n","      <td>0.002379</td>\n","      <td>0.007557</td>\n","      <td>-0.007870</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>0.005678</td>\n","      <td>-0.009664</td>\n","      <td>0.001840</td>\n","      <td>0.00650</td>\n","      <td>0.222700</td>\n","      <td>0.232347</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>0.004417</td>\n","      <td>0.001246</td>\n","      <td>0.240048</td>\n","      <td>0.232227</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.007632</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.0</td>\n","      <td>0.212278</td>\n","      <td>0.220136</td>\n","      <td>-0.008066</td>\n","      <td>0.002481</td>\n","      <td>0.000470</td>\n","      <td>4.405830</td>\n","      <td>-0.007088</td>\n","      <td>0.005668</td>\n","      <td>-0.004833</td>\n","      <td>-0.001299</td>\n","      <td>0.000618</td>\n","      <td>1.348367</td>\n","      <td>0.004436</td>\n","      <td>-0.003153</td>\n","      <td>-0.007243</td>\n","      <td>0.862369</td>\n","      <td>0.421491</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>0.010352</td>\n","      <td>0.005348</td>\n","      <td>0.615314</td>\n","      <td>0.408655</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>0.003492</td>\n","      <td>-0.002589</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>3.899294</td>\n","      <td>0.984962</td>\n","      <td>-0.008008</td>\n","      <td>0.001326</td>\n","      <td>-0.006496</td>\n","      <td>0.003065</td>\n","      <td>-0.003758</td>\n","      <td>-0.003128</td>\n","      <td>0.000260</td>\n","      <td>...</td>\n","      <td>-0.005313</td>\n","      <td>-0.004838</td>\n","      <td>0.006316</td>\n","      <td>-0.010068</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>0.095536</td>\n","      <td>0.031233</td>\n","      <td>-0.007870</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>0.005678</td>\n","      <td>0.218456</td>\n","      <td>0.001840</td>\n","      <td>0.00650</td>\n","      <td>2.578001</td>\n","      <td>2.687706</td>\n","      <td>0.001158</td>\n","      <td>0.167992</td>\n","      <td>0.004417</td>\n","      <td>0.163077</td>\n","      <td>2.665993</td>\n","      <td>2.903237</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>2.543015</td>\n","      <td>2.911643</td>\n","      <td>0.662859</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>-0.006222</td>\n","      <td>0.001637</td>\n","      <td>-0.008066</td>\n","      <td>0.002481</td>\n","      <td>0.000470</td>\n","      <td>-0.006442</td>\n","      <td>-0.007088</td>\n","      <td>0.005668</td>\n","      <td>-0.004833</td>\n","      <td>-0.001299</td>\n","      <td>0.000618</td>\n","      <td>-0.004086</td>\n","      <td>0.004436</td>\n","      <td>-0.003153</td>\n","      <td>-0.007243</td>\n","      <td>-0.002162</td>\n","      <td>0.312962</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>0.010352</td>\n","      <td>0.005348</td>\n","      <td>0.008442</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>0.003492</td>\n","      <td>-0.002589</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.005423</td>\n","      <td>1.479007</td>\n","      <td>-0.008008</td>\n","      <td>0.001326</td>\n","      <td>-0.006496</td>\n","      <td>0.003065</td>\n","      <td>6.426361</td>\n","      <td>6.426991</td>\n","      <td>5.035393</td>\n","      <td>...</td>\n","      <td>-0.005313</td>\n","      <td>-0.004838</td>\n","      <td>0.006316</td>\n","      <td>-0.010068</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>0.002379</td>\n","      <td>0.007557</td>\n","      <td>-0.007870</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>0.005678</td>\n","      <td>-0.009664</td>\n","      <td>0.001840</td>\n","      <td>0.00650</td>\n","      <td>-0.008367</td>\n","      <td>0.001280</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>0.004417</td>\n","      <td>0.001246</td>\n","      <td>0.008982</td>\n","      <td>0.001160</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.007632</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>-0.006222</td>\n","      <td>1.235590</td>\n","      <td>1.225888</td>\n","      <td>1.955507</td>\n","      <td>2.047491</td>\n","      <td>0.677871</td>\n","      <td>-0.007088</td>\n","      <td>1.273652</td>\n","      <td>1.229121</td>\n","      <td>1.625985</td>\n","      <td>1.612600</td>\n","      <td>-0.004086</td>\n","      <td>0.004436</td>\n","      <td>0.473693</td>\n","      <td>5.039421</td>\n","      <td>5.044501</td>\n","      <td>1.616488</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>0.400709</td>\n","      <td>5.052011</td>\n","      <td>5.055105</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>0.003492</td>\n","      <td>1.752570</td>\n","      <td>1.746235</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.005423</td>\n","      <td>-0.008794</td>\n","      <td>0.471540</td>\n","      <td>0.001326</td>\n","      <td>-0.006496</td>\n","      <td>0.003065</td>\n","      <td>-0.003758</td>\n","      <td>-0.003128</td>\n","      <td>0.000260</td>\n","      <td>...</td>\n","      <td>-0.005313</td>\n","      <td>-0.004838</td>\n","      <td>0.006316</td>\n","      <td>-0.010068</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>0.002379</td>\n","      <td>0.007557</td>\n","      <td>-0.007870</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>0.005678</td>\n","      <td>-0.009664</td>\n","      <td>0.001840</td>\n","      <td>0.00650</td>\n","      <td>-0.008367</td>\n","      <td>0.001280</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>0.004417</td>\n","      <td>0.001246</td>\n","      <td>0.008982</td>\n","      <td>0.001160</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.007632</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>-0.006222</td>\n","      <td>0.001637</td>\n","      <td>-0.008066</td>\n","      <td>0.002481</td>\n","      <td>0.000470</td>\n","      <td>-0.006442</td>\n","      <td>-0.007088</td>\n","      <td>0.005668</td>\n","      <td>-0.004833</td>\n","      <td>-0.001299</td>\n","      <td>0.000618</td>\n","      <td>-0.004086</td>\n","      <td>0.180681</td>\n","      <td>0.703967</td>\n","      <td>0.699877</td>\n","      <td>-0.002162</td>\n","      <td>0.004506</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>3.483867</td>\n","      <td>3.478863</td>\n","      <td>0.008442</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>3.477007</td>\n","      <td>3.470925</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.005423</td>\n","      <td>4.284713</td>\n","      <td>5.114036</td>\n","      <td>0.769906</td>\n","      <td>0.556541</td>\n","      <td>0.566102</td>\n","      <td>-0.003758</td>\n","      <td>0.999728</td>\n","      <td>0.488465</td>\n","      <td>...</td>\n","      <td>0.215450</td>\n","      <td>0.215925</td>\n","      <td>0.006316</td>\n","      <td>-0.010068</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>4.366529</td>\n","      <td>4.371707</td>\n","      <td>2.440177</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>4.369828</td>\n","      <td>4.354486</td>\n","      <td>2.449887</td>\n","      <td>0.00650</td>\n","      <td>-0.008367</td>\n","      <td>0.001280</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>3.374954</td>\n","      <td>0.464683</td>\n","      <td>0.008982</td>\n","      <td>0.001160</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>3.376280</td>\n","      <td>0.456996</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.007632</td>\n","      <td>-0.008584</td>\n","      <td>1.439395</td>\n","      <td>1.844512</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.0</td>\n","      <td>-0.006222</td>\n","      <td>4.480810</td>\n","      <td>4.471107</td>\n","      <td>0.002481</td>\n","      <td>0.000470</td>\n","      <td>-0.006442</td>\n","      <td>-0.007088</td>\n","      <td>4.484841</td>\n","      <td>4.474340</td>\n","      <td>-0.001299</td>\n","      <td>0.000618</td>\n","      <td>-0.004086</td>\n","      <td>0.004436</td>\n","      <td>-0.003153</td>\n","      <td>-0.007243</td>\n","      <td>-0.002162</td>\n","      <td>0.004506</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>0.010352</td>\n","      <td>0.005348</td>\n","      <td>0.008442</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>0.003492</td>\n","      <td>-0.002589</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.005423</td>\n","      <td>-0.008794</td>\n","      <td>-0.008008</td>\n","      <td>0.001326</td>\n","      <td>-0.006496</td>\n","      <td>0.003065</td>\n","      <td>-0.003758</td>\n","      <td>-0.003128</td>\n","      <td>0.000260</td>\n","      <td>...</td>\n","      <td>1.855130</td>\n","      <td>0.103618</td>\n","      <td>0.006316</td>\n","      <td>-0.010068</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>0.002379</td>\n","      <td>0.007557</td>\n","      <td>-0.007870</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>1.033851</td>\n","      <td>0.005678</td>\n","      <td>-0.009664</td>\n","      <td>0.001840</td>\n","      <td>0.00650</td>\n","      <td>0.279909</td>\n","      <td>1.024903</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>0.004417</td>\n","      <td>0.001246</td>\n","      <td>0.297257</td>\n","      <td>0.833168</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.007632</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3.0</td>\n","      <td>-0.006222</td>\n","      <td>0.001637</td>\n","      <td>-0.008066</td>\n","      <td>0.002481</td>\n","      <td>0.000470</td>\n","      <td>-0.006442</td>\n","      <td>-0.007088</td>\n","      <td>0.005668</td>\n","      <td>-0.004833</td>\n","      <td>-0.001299</td>\n","      <td>0.000618</td>\n","      <td>-0.004086</td>\n","      <td>0.004436</td>\n","      <td>-0.003153</td>\n","      <td>0.239105</td>\n","      <td>0.244186</td>\n","      <td>0.004506</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>0.010352</td>\n","      <td>0.754745</td>\n","      <td>0.757839</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>0.003492</td>\n","      <td>-0.002589</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.005423</td>\n","      <td>-0.008794</td>\n","      <td>-0.008008</td>\n","      <td>0.001326</td>\n","      <td>-0.006496</td>\n","      <td>0.003065</td>\n","      <td>-0.003758</td>\n","      <td>-0.003128</td>\n","      <td>0.000260</td>\n","      <td>...</td>\n","      <td>-0.005313</td>\n","      <td>-0.004838</td>\n","      <td>0.561043</td>\n","      <td>0.232108</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>0.002379</td>\n","      <td>0.007557</td>\n","      <td>-0.007870</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>0.005678</td>\n","      <td>-0.009664</td>\n","      <td>0.001840</td>\n","      <td>0.00650</td>\n","      <td>-0.008367</td>\n","      <td>0.001280</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>0.004417</td>\n","      <td>0.001246</td>\n","      <td>0.008982</td>\n","      <td>0.001160</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.007632</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.0</td>\n","      <td>0.521082</td>\n","      <td>4.718698</td>\n","      <td>4.708996</td>\n","      <td>0.806908</td>\n","      <td>0.000470</td>\n","      <td>-0.006442</td>\n","      <td>2.761354</td>\n","      <td>6.709153</td>\n","      <td>6.698652</td>\n","      <td>0.803128</td>\n","      <td>0.000618</td>\n","      <td>-0.004086</td>\n","      <td>0.004436</td>\n","      <td>5.632624</td>\n","      <td>5.628534</td>\n","      <td>-0.002162</td>\n","      <td>0.004506</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>0.010352</td>\n","      <td>0.005348</td>\n","      <td>0.008442</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>0.670131</td>\n","      <td>0.003492</td>\n","      <td>-0.002589</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.681901</td>\n","      <td>-0.008794</td>\n","      <td>-0.008008</td>\n","      <td>0.001326</td>\n","      <td>-0.006496</td>\n","      <td>0.122656</td>\n","      <td>-0.003758</td>\n","      <td>-0.003128</td>\n","      <td>0.000260</td>\n","      <td>...</td>\n","      <td>-0.005313</td>\n","      <td>-0.004838</td>\n","      <td>0.006316</td>\n","      <td>-0.010068</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>0.002379</td>\n","      <td>0.007557</td>\n","      <td>4.153725</td>\n","      <td>2.884594</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>0.005678</td>\n","      <td>-0.009664</td>\n","      <td>2.337350</td>\n","      <td>2.34201</td>\n","      <td>-0.008367</td>\n","      <td>0.001280</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>0.004417</td>\n","      <td>0.001246</td>\n","      <td>0.008982</td>\n","      <td>0.001160</td>\n","      <td>0.049496</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.052854</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.0</td>\n","      <td>-0.006222</td>\n","      <td>0.001637</td>\n","      <td>-0.008066</td>\n","      <td>0.002481</td>\n","      <td>0.000470</td>\n","      <td>-0.006442</td>\n","      <td>-0.007088</td>\n","      <td>0.005668</td>\n","      <td>-0.004833</td>\n","      <td>-0.001299</td>\n","      <td>0.000618</td>\n","      <td>-0.004086</td>\n","      <td>0.004436</td>\n","      <td>-0.003153</td>\n","      <td>-0.007243</td>\n","      <td>-0.002162</td>\n","      <td>0.004506</td>\n","      <td>0.002253</td>\n","      <td>0.369135</td>\n","      <td>0.372388</td>\n","      <td>0.597696</td>\n","      <td>0.008442</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>0.003492</td>\n","      <td>0.589758</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.005423</td>\n","      <td>1.321921</td>\n","      <td>1.545321</td>\n","      <td>0.001326</td>\n","      <td>-0.006496</td>\n","      <td>0.003065</td>\n","      <td>-0.003758</td>\n","      <td>-0.003128</td>\n","      <td>0.000260</td>\n","      <td>...</td>\n","      <td>0.345608</td>\n","      <td>-0.004838</td>\n","      <td>0.006316</td>\n","      <td>2.127479</td>\n","      <td>0.005767</td>\n","      <td>1.072123</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>0.002379</td>\n","      <td>0.007557</td>\n","      <td>-0.007870</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>0.494782</td>\n","      <td>0.479440</td>\n","      <td>0.001840</td>\n","      <td>0.00650</td>\n","      <td>-0.008367</td>\n","      <td>0.001280</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>0.004417</td>\n","      <td>0.001246</td>\n","      <td>0.008982</td>\n","      <td>0.001160</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.007632</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3.0</td>\n","      <td>-0.006222</td>\n","      <td>0.001637</td>\n","      <td>-0.008066</td>\n","      <td>0.002481</td>\n","      <td>0.000470</td>\n","      <td>-0.006442</td>\n","      <td>-0.007088</td>\n","      <td>0.005668</td>\n","      <td>-0.004833</td>\n","      <td>-0.001299</td>\n","      <td>0.000618</td>\n","      <td>-0.004086</td>\n","      <td>0.004436</td>\n","      <td>-0.003153</td>\n","      <td>-0.007243</td>\n","      <td>-0.002162</td>\n","      <td>0.004506</td>\n","      <td>0.002253</td>\n","      <td>0.007099</td>\n","      <td>0.010352</td>\n","      <td>0.005348</td>\n","      <td>0.008442</td>\n","      <td>-0.008331</td>\n","      <td>0.008585</td>\n","      <td>-0.006346</td>\n","      <td>0.003492</td>\n","      <td>-0.002589</td>\n","      <td>-0.008925</td>\n","      <td>0.009793</td>\n","      <td>-0.002807</td>\n","      <td>0.005423</td>\n","      <td>-0.008794</td>\n","      <td>-0.008008</td>\n","      <td>0.001326</td>\n","      <td>-0.006496</td>\n","      <td>0.003065</td>\n","      <td>-0.003758</td>\n","      <td>-0.003128</td>\n","      <td>0.000260</td>\n","      <td>...</td>\n","      <td>-0.005313</td>\n","      <td>-0.004838</td>\n","      <td>0.006316</td>\n","      <td>-0.010068</td>\n","      <td>0.005767</td>\n","      <td>-0.006269</td>\n","      <td>-0.006344</td>\n","      <td>-0.004685</td>\n","      <td>-0.006450</td>\n","      <td>0.001465</td>\n","      <td>0.002379</td>\n","      <td>0.007557</td>\n","      <td>-0.007870</td>\n","      <td>0.000155</td>\n","      <td>-0.007163</td>\n","      <td>0.010229</td>\n","      <td>0.005678</td>\n","      <td>-0.009664</td>\n","      <td>0.001840</td>\n","      <td>0.00650</td>\n","      <td>-0.008367</td>\n","      <td>0.001280</td>\n","      <td>0.001158</td>\n","      <td>-0.009661</td>\n","      <td>0.004417</td>\n","      <td>0.001246</td>\n","      <td>0.008982</td>\n","      <td>0.001160</td>\n","      <td>0.004275</td>\n","      <td>0.009444</td>\n","      <td>0.005743</td>\n","      <td>-0.006441</td>\n","      <td>-0.004304</td>\n","      <td>0.009567</td>\n","      <td>0.007632</td>\n","      <td>-0.008584</td>\n","      <td>-0.005680</td>\n","      <td>0.010111</td>\n","      <td>0.007561</td>\n","      <td>0.00375</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 9217 columns</p>\n","</div>"],"text/plain":["   0         1         2         3     ...      9213      9214      9215     9216\n","0   3.0 -0.006222  0.001637 -0.008066  ... -0.005680  0.010111  0.007561  0.00375\n","1   4.0  0.212278  0.220136 -0.008066  ... -0.005680  0.010111  0.007561  0.00375\n","2   2.0 -0.006222  0.001637 -0.008066  ... -0.005680  0.010111  0.007561  0.00375\n","3   2.0 -0.006222  1.235590  1.225888  ... -0.005680  0.010111  0.007561  0.00375\n","4   0.0 -0.006222  0.001637 -0.008066  ...  1.439395  1.844512  0.007561  0.00375\n","5   2.0 -0.006222  4.480810  4.471107  ... -0.005680  0.010111  0.007561  0.00375\n","6   3.0 -0.006222  0.001637 -0.008066  ... -0.005680  0.010111  0.007561  0.00375\n","7   0.0  0.521082  4.718698  4.708996  ... -0.005680  0.010111  0.007561  0.00375\n","8   4.0 -0.006222  0.001637 -0.008066  ... -0.005680  0.010111  0.007561  0.00375\n","9   3.0 -0.006222  0.001637 -0.008066  ... -0.005680  0.010111  0.007561  0.00375\n","\n","[10 rows x 9217 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"0eY_5DRpj8xX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592556586209,"user_tz":-120,"elapsed":399,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":[""],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"zoSiqCaxnyEn","colab_type":"code","colab":{}},"source":["###############################################################################\n","# visualize train data\n","daisy = where(Y == 0.0)\n","dandelion = where(Y ==1.0)\n","rose = where(Y ==2.0)\n","sunflower = where(Y ==3.0)\n","tulip = where(Y ==4.0)\n","\n","# 'b', 'g', 'r', 'c', 'm', 'y', 'k', 'w' - they are the single\n","#   character short-hand notations for blue, green, red, cyan, \n","# magenta, yellow, black, and white.\n","ran_feat_1 = [randrange(1,9216) for i in range(10)]\n","ran_feat_2 = [randrange(1,9216) for i in range(10)]\n","\n","for i in ran_feat_1:\n","  for j in ran_feat_2:\n","    scatter(X.iloc[daisy[0], i], X.iloc[daisy[0], j], marker='1', c='r')\n","    scatter(X.iloc[dandelion[0], i], X.iloc[dandelion[0], j], marker='o', c='g')\n","    scatter(X.iloc[rose[0], i], X.iloc[rose[0], j], marker='s', c='b')\n","    scatter(X.iloc[sunflower[0], i], X.iloc[sunflower[0], j], marker='p', c='y')\n","    scatter(X.iloc[tulip[0], i], X.iloc[tulip[0], j], marker='*', c='c')\n","\n","    xlabel('Training set - Exam the feature %s' % str(i))\n","    ylabel('Training set - Exam the feature %s' % str(j))\n","    legend(['Daisy', 'Dandelion', 'Rose', 'Sunflower', 'Tulip'])\n","    show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfpNXB5Qo-PU","colab_type":"code","colab":{}},"source":["print (X.iloc[daisy[0], 0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yrKUcNPZnEJU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1592565262833,"user_tz":-120,"elapsed":81829,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"943bc5f4-1551-42be-83ea-18701045c343"},"source":["# Train SVM Classifier - Kernel: Linear\n","SVM_Linear_Classifier = SVC(kernel='linear')\n","linear_pipeline = Pipeline([('low_variance_filter', VarianceThreshold()), ('model', SVM_Linear_Classifier)])\n","linear_pipeline.fit(X, Y)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","         steps=[('low_variance_filter', VarianceThreshold(threshold=0.0)),\n","                ('model',\n","                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n","                     coef0=0.0, decision_function_shape='ovr', degree=3,\n","                     gamma='scale', kernel='linear', max_iter=-1,\n","                     probability=False, random_state=None, shrinking=True,\n","                     tol=0.001, verbose=False))],\n","         verbose=False)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"ffdAGUYJnFKD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1592565396265,"user_tz":-120,"elapsed":127847,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"ceb283fa-51bd-465e-ea6a-c4313717f19e"},"source":["# Train SVM Classifier - Kernel: Quadratic\n","SVM_Quadratic_Classifier = SVC(kernel='rbf')\n","quad_pipeline = Pipeline([('low_variance_filter', VarianceThreshold()), ('model', SVM_Quadratic_Classifier)])\n","quad_pipeline.fit(X, Y)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","         steps=[('low_variance_filter', VarianceThreshold(threshold=0.0)),\n","                ('model',\n","                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n","                     coef0=0.0, decision_function_shape='ovr', degree=3,\n","                     gamma='scale', kernel='rbf', max_iter=-1,\n","                     probability=False, random_state=None, shrinking=True,\n","                     tol=0.001, verbose=False))],\n","         verbose=False)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"yqFp3_SmnZYC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1592565491518,"user_tz":-120,"elapsed":89198,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"b78b9e18-8d1e-463f-a09f-d98f66f564be"},"source":["# Train SVM Classifier - Kernel: Polynomial\n","SVM_Polynomial_Classifier = SVC(kernel='poly', degree=1)\n","poly_pipeline = Pipeline([('low_variance_filter', VarianceThreshold()), ('model', SVM_Polynomial_Classifier)])\n","poly_pipeline.fit(X, Y)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","         steps=[('low_variance_filter', VarianceThreshold(threshold=0.0)),\n","                ('model',\n","                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n","                     coef0=0.0, decision_function_shape='ovr', degree=1,\n","                     gamma='scale', kernel='poly', max_iter=-1,\n","                     probability=False, random_state=None, shrinking=True,\n","                     tol=0.001, verbose=False))],\n","         verbose=False)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"-VDtOSzRMfIE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592565548872,"user_tz":-120,"elapsed":48129,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["def validation_statistics():\n","    pipelines = [linear_pipeline, quad_pipeline, poly_pipeline]\n","    \n","    for pipeline in pipelines:\n","\n","        preds = pipeline.predict(X_val)\n","\n","        correct = 0\n","        correct_daisy = 0\n","        correct_dandelion = 0\n","        correct_rose = 0\n","        correct_sunflower = 0\n","        correct_tulip = 0\n","        # calculate number of each type of flowers\n","        num_daisy = len(where(Y_val == 0)[0])\n","        num_dandelion = len(where(Y_val == 1)[0])\n","        num_rose = len(where(Y_val == 2)[0])\n","        num_sunflower = len(where(Y_val == 3)[0])\n","        num_tulip = len(where(Y_val == 4)[0])\n","        for i in range(0,len(Y_val)):\n","            actual_val = int(Y_val[i])\n","            validate_val = int(preds[i])\n","            if (actual_val == validate_val):\n","              correct += 1\n","              if(actual_val == 0):\n","                  correct_daisy += 1\n","              if(actual_val == 1):\n","                  correct_dandelion += 1\n","              if(actual_val == 2):\n","                  correct_rose += 1\n","              if(actual_val == 3):\n","                  correct_sunflower += 1\n","              if(actual_val == 4):\n","                  correct_tulip += 1\n","\n","        acc = float(correct/len(Y_val))\n","        acc_daisy = float(correct_daisy/num_daisy)\n","        acc_dandelion = float(correct_dandelion/num_dandelion)\n","        acc_rose = float(correct_rose/num_rose)\n","        acc_sunflower = float(correct_sunflower/num_sunflower)\n","        acc_tulip = float(correct_tulip/num_tulip)\n","\n","        # save the statistics\n","        with open('validation_statistics.txt', 'a+') as f:\n","            f.write('%.3f %.3f %.3f  %.3f  %.3f  %.3f\\n' % \n","                    (acc, acc_daisy, acc_dandelion, acc_rose, acc_sunflower, acc_tulip))\n","\n","validation_statistics()"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aNbOhQ9OE3d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592564249535,"user_tz":-120,"elapsed":590,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"93919709-ebcf-4022-8c9d-fa301af96e27"},"source":["num_daisy = len(where(Y_val == 0)[0])\n","print (num_daisy)"],"execution_count":121,"outputs":[{"output_type":"stream","text":["113\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pob4lD0OamgT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592565037686,"user_tz":-120,"elapsed":546,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["# Validating the trained SVM classifiers\n","def validation_trained_SVM_classifier(svm_kernel):\n","    if svm_kernel == 'linear':\n","        preds = linear_pipeline.predict(X_val)\n","    if svm_kernel == 'rbf':\n","        preds = quad_pipeline.predict(X_val)\n","    if svm_kernel == 'poly':\n","        preds = poly_pipeline.predict(X_val)\n","\n","    correct = 0\n","    for i in range(0,len(Y_val)):\n","        actual_val = int(Y_val[i])\n","        validate_val = int(preds[i])\n","        if (actual_val == validate_val):\n","          correct += 1\n","\n","    acc = float(correct/len(Y_val))\n","\n","    print ('Accuracy: %.3f' % acc)\n","    \n","    return preds"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4sGkVxtegb3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"error","timestamp":1592565043599,"user_tz":-120,"elapsed":515,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"39b00d58-cf7b-4433-edb9-52938e008b37"},"source":["# validate the model\n","preds = validation_trained_SVM_classifier('linear')"],"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e3d00b00cbd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# validate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_trained_SVM_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-35b8155e5637>\u001b[0m in \u001b[0;36mvalidation_trained_SVM_classifier\u001b[0;34m(svm_kernel)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_trained_SVM_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msvm_kernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msvm_kernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rbf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquad_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'linear_pipeline' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ZKxYGgki-NyJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592560452002,"user_tz":-120,"elapsed":20182,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"a551336f-5298-4c23-a7d7-c7fbd68f6398"},"source":["preds = validation_trained_SVM_classifier('rbf')"],"execution_count":96,"outputs":[{"output_type":"stream","text":["Accuracy: 0.862\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ci3dkK6Z-Ryi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592561701488,"user_tz":-120,"elapsed":15770,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}},"outputId":"a7a594bb-50bd-4ac1-e706-9e0b1bf45988"},"source":["preds = validation_trained_SVM_classifier('poly')"],"execution_count":103,"outputs":[{"output_type":"stream","text":["Accuracy: 0.866\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cv5lX8OZstT7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592562159796,"user_tz":-120,"elapsed":5580,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["def get_images_features_for_testing():\n","\n","    # Iterate over vallidation data.\n","    # pick randomly 3x4 images for testing\n","    test_indices = [randrange(0, int(len(dataloaders['val'])/4)) for i in range(0,3)]\n","\n","    test_img_data = []\n","    test_img_features = []\n","    \n","    for idx, (inputs, labels) in enumerate(dataloaders['val']):\n","        if idx in test_indices:\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # get features outputs\n","            features = model(inputs).cpu()\n","\n","            batch_size = features.shape[0] \n","            \n","            for i in range(0, batch_size):  \n","                img_data = inputs.cpu().data[i]\n","                featr = np.array(features[i].cpu())\n","                label = int(labels[i].cpu().numpy())\n","\n","                # store data and label\n","                test_img_data.append(img_data)\n","                test_img_features.append(np.append(label, featr))\n","    \n","    return (test_img_data, test_img_features)\n","\n","# extract features for testing the model\n","test_img_data, test_img_features = get_images_features_for_testing()"],"execution_count":112,"outputs":[]},{"cell_type":"code","metadata":{"id":"-C7cPzDza0IG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592561904942,"user_tz":-120,"elapsed":1018,"user":{"displayName":"Khánh Đỗ Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCgKXNyvBUEmSPJLY3MI2SgylEZUwLA90gh3U--w=s64","userId":"03913380677606768273"}}},"source":["# Show pridictions result for testing data\n","def show_testing_result(pipeline):\n","    test_dataset = pd.DataFrame(test_img_features)\n","\n","    Y_test = test_dataset.iloc[:, 0]\n","    X_test = test_dataset.iloc[:, 1:]\n","\n","    preds_test = pipeline.predict(X_test)\n","\n","\n","    row = 3\n","    col = 4\n","    f, ax = plt.subplots(row, col, figsize=(10,10))\n","\n","    for i in range(row):\n","      for j in range(col):\n","        inp = test_img_data[col*i+j]\n","        inp = inp.numpy().transpose((1, 2, 0))\n","        mean = np.array([0.485, 0.456, 0.406])\n","        std = np.array([0.229, 0.224, 0.225])\n","        inp = std * inp + mean\n","        inp = np.clip(inp, 0, 1)\n","\n","        ax[i,j].imshow(inp)\n","        ax[i,j].text(5, -13, 'Predicted: %s' % class_names[int(preds_test[col*i+j])],\n","                    color='k', backgroundcolor='red', alpha=0.9)\n","        # ax[i,j].text(25, -5, 'Pred:   %s\\nActual:%s' % (class_names[int(preds_test[col*i+j])], class_names[int(Y_test[col*i+j])]),\n","        #              color='k', backgroundcolor='red', alpha=0.8)\n","\n","    plt.show()\n"],"execution_count":107,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZvKgUYsFsV_","colab_type":"code","colab":{}},"source":["show_testing_result(linear_pipeline)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6k8rhBfVGFui","colab_type":"code","colab":{}},"source":["show_testing_result(quad_pipeline)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeEeDd44GjNH","colab_type":"code","colab":{}},"source":["show_testing_result(poly_pipeline)"],"execution_count":null,"outputs":[]}]}